{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Exercise 4-Question.ipynb","provenance":[{"file_id":"https://github.com/lmoroney/dlaicourse/blob/master/Exercises/Exercise%204%20-%20Handling%20Complex%20Images/Exercise%204-Question.ipynb","timestamp":1609344510015}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"zX4Kg8DUTKWO"},"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UncprnB0ymAE"},"source":["Below is code with a link to a happy or sad dataset which contains 80 images, 40 happy and 40 sad. \n","Create a convolutional neural network that trains to 100% accuracy on these images,  which cancels training upon hitting training accuracy of >.999\n","\n","Hint -- it will work best with 3 convolutional layers."]},{"cell_type":"code","metadata":{"id":"7Vti6p3PxmpS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609346880553,"user_tz":300,"elapsed":654,"user":{"displayName":"Avinash Sooriyarachchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBN874taxbqJq0e2Ju_KOly05ZGjm8qkoIdRs3Aw=s64","userId":"05307762625020600141"}},"outputId":"19f7bd85-a1f4-4b0e-c745-5b77812df6f1"},"source":["import tensorflow as tf\n","import os\n","import zipfile\n","\n","\n","DESIRED_ACCURACY = 0.999\n","\n","!wget --no-check-certificate \\\n","    \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/happy-or-sad.zip\" \\\n","    -O \"/tmp/happy-or-sad.zip\"\n","\n","zip_ref = zipfile.ZipFile(\"/tmp/happy-or-sad.zip\", 'r')\n","zip_ref.extractall(\"/tmp/h-or-s\")\n","zip_ref.close()\n","\n","class myCallback(tf.keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs = {}):\n","    if (logs.get('accuracy')>0.999):\n","      print('\\nReached 99.9% training acuracy so cancelling training!')\n","      self.model.stop_training = True\n","\n","  # Your Code\n","\n","callbacks = myCallback()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-12-30 16:48:00--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/happy-or-sad.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.189.128, 2404:6800:4008:c06::80, 2404:6800:4008:c07::80, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.189.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2670333 (2.5M) [application/zip]\n","Saving to: ‘/tmp/happy-or-sad.zip’\n","\n","\r/tmp/happy-or-sad.z   0%[                    ]       0  --.-KB/s               \r/tmp/happy-or-sad.z 100%[===================>]   2.55M  --.-KB/s    in 0.02s   \n","\n","2020-12-30 16:48:00 (133 MB/s) - ‘/tmp/happy-or-sad.zip’ saved [2670333/2670333]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6DLGbXXI1j_V"},"source":["# This Code Block should Define and Compile the Model\n","model = tf.keras.models.Sequential([\n","      tf.keras.layers.Conv2D(16, (3,3), activation = 'relu', input_shape = (150,150,3)),\n","      tf.keras.layers.MaxPooling2D(2,2),\n","      tf.keras.layers.Conv2D(32,(3,3), activation='relu'),\n","      tf.keras.layers.MaxPooling2D(2,2),\n","      tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n","      tf.keras.layers.MaxPooling2D(2,2),\n","      tf.keras.layers.Flatten(),\n","      tf.keras.layers.Dense(512, activation='relu'),\n","      tf.keras.layers.Dense(1,activation='sigmoid')\n","])\n","\n","from tensorflow.keras.optimizers import RMSprop\n","\n","model.compile(loss = 'binary_crossentropy', optimizer=RMSprop(lr=0.001), metrics = ['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Ap9fUJE1vVu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609347477663,"user_tz":300,"elapsed":1259,"user":{"displayName":"Avinash Sooriyarachchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBN874taxbqJq0e2Ju_KOly05ZGjm8qkoIdRs3Aw=s64","userId":"05307762625020600141"}},"outputId":"1645d116-e3f5-41f0-b71a-cfd0b713f067"},"source":["# This code block should create an instance of an ImageDataGenerator called train_datagen \n","# And a train_generator by calling train_datagen.flow_from_directory\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","train_datagen = ImageDataGenerator(rescale=1/255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    '/tmp/h-or-s/',\n","    target_size=(150,150),\n","    batch_size=10,\n","    class_mode='binary')\n","        # Your Code Here)\n","\n","# Expected output: 'Found 80 images belonging to 2 classes'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 80 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"48dLm13U1-Le","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609347497601,"user_tz":300,"elapsed":18699,"user":{"displayName":"Avinash Sooriyarachchi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBN874taxbqJq0e2Ju_KOly05ZGjm8qkoIdRs3Aw=s64","userId":"05307762625020600141"}},"outputId":"5e255fea-43ae-4f0f-dbc0-27b3ea21510e"},"source":["# This code block should call model.fit and train for\n","# a number of epochs. \n","history = model.fit(\n","      # Your Code Here\n","      train_generator,\n","      epochs = 20,\n","      steps_per_epoch = 8,\n","      verbose=2,\n","      callbacks = [callbacks]\n","      )\n","    \n","# Expected output: \"Reached 99.9% accuracy so cancelling training!\"\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","8/8 - 3s - loss: 1.9912 - accuracy: 0.5750\n","Epoch 2/20\n","8/8 - 2s - loss: 0.6145 - accuracy: 0.7375\n","Epoch 3/20\n","8/8 - 2s - loss: 0.2982 - accuracy: 0.9000\n","Epoch 4/20\n","8/8 - 2s - loss: 0.2412 - accuracy: 0.8625\n","Epoch 5/20\n","8/8 - 2s - loss: 0.2494 - accuracy: 0.9125\n","Epoch 6/20\n","8/8 - 2s - loss: 0.0867 - accuracy: 0.9750\n","Epoch 7/20\n","8/8 - 2s - loss: 0.0696 - accuracy: 0.9625\n","Epoch 8/20\n","8/8 - 2s - loss: 0.0222 - accuracy: 1.0000\n","\n","Reached 99.9% training acuracy so cancelling training!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-ackvhL_jDqS"},"source":[""],"execution_count":null,"outputs":[]}]}
